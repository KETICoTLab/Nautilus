from kubernetes import client, config
from typing import Optional
import subprocess
import shlex
from kubernetes.stream import stream
import time
# def get_kubernetes_nodes():
#     # Kubernetes í´ë¼ì´ì–¸íŠ¸ êµ¬ì„±ì„ ë¡œë“œí•©ë‹ˆë‹¤ (ë¡œì»¬ kubeconfig íŒŒì¼ ì‚¬ìš©)
#     config.load_kube_config()
    
#     # CoreV1 API í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤
#     v1 = client.CoreV1Api()
    
#     # ë…¸ë“œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
#     print("Listing Kubernetes nodes:")
#     try:
#         nodes = v1.list_node()
#         print(nodes.items[0])
#         for node in nodes.items:
#             print(f"Node Name: {node.metadata.name}")
#             for address in node.status.addresses:
#                 print(f"  Type: {address.type}, Address: {address.address}")
#             print(f"  Node Status: {node.status.conditions[-1].type} - {node.status.conditions[-1].status}")
#             print("-" * 40)
#     except Exception as e:
#         print(f"An error occurred: {e}")

# if __name__ == "__main__":
#     get_kubernetes_nodes()



# Kubernetes í´ëŸ¬ìŠ¤í„° ì„¤ì • ë¡œë“œ

try:
    config.load_kube_config()  # ë¡œì»¬ K8s í´ëŸ¬ìŠ¤í„° (kubectl ì‚¬ìš© ê°€ëŠ¥ ì‹œ)
except config.ConfigException:
    config.load_incluster_config()  # í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ ì‹¤í–‰ ì‹œ

# API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
v1 = client.CoreV1Api()
apps_v1 = client.AppsV1Api()
batch_v1 = client.BatchV1Api()
storage_v1 = client.StorageV1Api()

# --- Kubernetes ë¦¬ì†ŒìŠ¤ ì¡°íšŒ í•¨ìˆ˜ë“¤ --- #
def node_has_gpu(node_name: str) -> bool:
    """
    í•´ë‹¹ ë…¸ë“œê°€ GPU(nvidia.com/gpu)ë¥¼ ë³´ìœ í•˜ê³  ìˆëŠ”ì§€ í™•ì¸
    ì˜ˆì œ)
    use_gpu = node_has_gpu("w-kr-pr-test03")
    create_client_deployment(
        project_id="p-kr-prtest09",
        site=1,
        node_name="w-kr-pr-test03",
        use_gpu=use_gpu
    )
    """
    try:
        node = v1.read_node(name=node_name)
        allocatable = node.status.allocatable or {}
        gpu_count = allocatable.get("nvidia.com/gpu", "0")
        return int(gpu_count) > 0
    except Exception as e:
        print(f"âš ï¸ Failed to check GPU for node '{node_name}': {e}")
        return False

def list_daemon_set_for_all_namespace():
    """ëª¨ë“  ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ DaemonSet ëª©ë¡ ì¡°íšŒ"""
    return apps_v1.list_daemon_set_for_all_namespaces()

def list_deployment_for_all_namespace():
    """ëª¨ë“  ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ Deployment ëª©ë¡ ì¡°íšŒ"""
    return apps_v1.list_deployment_for_all_namespaces()

def list_namespaced_daemon_set(namespace: str):
    """íŠ¹ì • ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ DaemonSet ëª©ë¡ ì¡°íšŒ"""
    return apps_v1.list_namespaced_daemon_set(namespace)

def list_namespaced_deployment(namespace: str):
    """íŠ¹ì • ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ Deployment ëª©ë¡ ì¡°íšŒ"""
    return apps_v1.list_namespaced_deployment(namespace)

def list_namespaced_replica_set(namespace: str):
    """íŠ¹ì • ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ ReplicaSet ëª©ë¡ ì¡°íšŒ"""
    return apps_v1.list_namespaced_replica_set(namespace)

def list_replica_set_for_all_namespaces():
    """ëª¨ë“  ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ ReplicaSet ëª©ë¡ ì¡°íšŒ"""
    return apps_v1.list_replica_set_for_all_namespaces()

def list_stateful_set_for_all_namespaces():
    """ëª¨ë“  ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ StatefulSet ëª©ë¡ ì¡°íšŒ"""
    return apps_v1.list_stateful_set_for_all_namespaces()

def list_cron_job_for_all_namespaces():
    """ëª¨ë“  ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ CronJob ëª©ë¡ ì¡°íšŒ"""
    return batch_v1.list_cron_job_for_all_namespaces()

def list_job_for_all_namespaces():
    """ëª¨ë“  ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ Job ëª©ë¡ ì¡°íšŒ"""
    return batch_v1.list_job_for_all_namespaces()

def list_namespaced_cron_job(namespace: str):
    """íŠ¹ì • ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ CronJob ëª©ë¡ ì¡°íšŒ"""
    return batch_v1.list_namespaced_cron_job(namespace)

def list_namespaced_job(namespace: str):
    """íŠ¹ì • ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ Job ëª©ë¡ ì¡°íšŒ"""
    return batch_v1.list_namespaced_job(namespace)

def list_persistent_volume():
    """ëª¨ë“  Persistent Volume ì¡°íšŒ"""
    return v1.list_persistent_volume()

def list_persistent_volume_claim_for_all_namespaces():
    """ëª¨ë“  ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ Persistent Volume Claim ì¡°íšŒ"""
    return v1.list_persistent_volume_claim_for_all_namespaces()

def list_namespaced_persistent_volume_claim(namespace: str):
    """íŠ¹ì • ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ Persistent Volume Claim ì¡°íšŒ"""
    return v1.list_namespaced_persistent_volume_claim(namespace)

def list_node():
    """í´ëŸ¬ìŠ¤í„° ë‚´ ëª¨ë“  ë…¸ë“œ ì¡°íšŒ"""
    return v1.list_node()

def custom_list_node():
    """í´ëŸ¬ìŠ¤í„° ë‚´ ëª¨ë“  ë…¸ë“œì˜ í•„ìš”í•œ ì •ë³´ë§Œ ë°˜í™˜"""
    nodes = v1.list_node()
    
    node_list = []
    
    for node in nodes.items:
        metadata = node.metadata
        status = node.status
        
        # ë…¸ë“œ ì´ë¦„
        node_name = metadata.name

        # ë…¸ë“œ ì—­í• (Role) ì°¾ê¸°
        labels = metadata.labels or {}
        role = "unknown"
        for key in labels:
            if key.startswith("node-role.kubernetes.io/"):
                role = key.split("/")[-1]
                break
        
        # CPU ë° ë©”ëª¨ë¦¬ ì •ë³´
        capacity = status.capacity or {}
        cpu = capacity.get("cpu", "unknown")
        memory = capacity.get("memory", "unknown")

        # Internal IP ì°¾ê¸°
        addresses = status.addresses or []
        internal_ip = next((addr.address for addr in addresses if addr.type == "InternalIP"), "unknown")

        # ë…¸ë“œ ìƒíƒœ (Ready ì—¬ë¶€)
        conditions = status.conditions or []
        ready_status = next((cond.status for cond in conditions if cond.type == "Ready"), "False")

        # ê²°ê³¼ ì €ì¥
        node_list.append({
            "node_name": node_name,
            "cpu": cpu,
            "memory": memory,
            "ip": internal_ip,
            "ready": ready_status == "True"
        })

    return node_list

def list_pod_for_all_namespaces():
    """ëª¨ë“  ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ Pod ëª©ë¡ ì¡°íšŒ"""
    return v1.list_pod_for_all_namespaces()

def list_namespaced_pod(namespace: str):
    """íŠ¹ì • ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ Pod ëª©ë¡ ì¡°íšŒ"""
    return v1.list_namespaced_pod(namespace)

def get_pod_name_by_deployment(deployment_name: str, namespace: str = "nautilus", retry: int = 5, wait: int = 3):
    """Deploymentê°€ ìƒì„±í•œ Podì˜ ì´ë¦„ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ (ì¬ì‹œë„ í¬í•¨)"""
    v1 = client.CoreV1Api()

    for attempt in range(retry):
        pod_list = v1.list_namespaced_pod(namespace=namespace, label_selector="app=nautilus")
        for pod in pod_list.items:
            pod_name = pod.metadata.name
            if pod_name.startswith(deployment_name):
                print(f"[âœ… found] pod: {pod_name}")
                return pod_name

        print(f"[{attempt+1}/{retry}] pod for '{deployment_name}' not found yet, retrying in {wait}s...")
        time.sleep(wait)

    print(f"[âŒ failed] No pod found for deployment '{deployment_name}' after {retry} retries.")
    return None

def list_pods_by_deployment(deployment_name: str, namespace: str = "nautilus"):
    """Deploymentê°€ ìƒì„±í•œ ëª¨ë“  Podì˜ ì´ë¦„ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    # í•´ë‹¹ Deploymentì˜ Pod ëª©ë¡ ì¡°íšŒ
    pod_list = v1.list_namespaced_pod(namespace=namespace, label_selector=f"app={deployment_name}")

    pod_names = [pod.metadata.name for pod in pod_list.items]

    return pod_names  # ëª¨ë“  Pod ì´ë¦„ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

def list_service_for_all_namespace():
    """ëª¨ë“  ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ Service ëª©ë¡ ì¡°íšŒ"""
    return v1.list_service_for_all_namespaces()

def list_namespaced_service(namespace: str):
    """íŠ¹ì • ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ Service ëª©ë¡ ì¡°íšŒ"""
    return v1.list_namespaced_service(namespace)

def list_storage_class():
    """ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ ì¡°íšŒ"""
    return storage_v1.list_storage_class()

def list_volume_attachment():
    """ë³¼ë¥¨ ì–´íƒœì¹˜ë¨¼íŠ¸ ì¡°íšŒ"""
    return storage_v1.list_volume_attachment()

def list_namespace():
    return v1.list_namespace()

def is_exist_namespace(namespace: str) -> bool:
    """ì£¼ì–´ì§„ namespaceê°€ ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„°ì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜."""
    try:
        namespaces = v1.list_namespace()  # ëª¨ë“  namespace ëª©ë¡ ì¡°íšŒ
        
        # ì£¼ì–´ì§„ namespaceê°€ ëª©ë¡ì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        return any(ns.metadata.name == namespace for ns in namespaces.items)
    
    except client.exceptions.ApiException as e:
        print(f"âŒ Kubernetes namespace ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return False

# --- Kubernetes ë¦¬ì†ŒìŠ¤ ìƒì„± í•¨ìˆ˜ë“¤ --- #
def create_namespace(name: str):
    """ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±"""
    body = client.V1Namespace(metadata=client.V1ObjectMeta(name=name))
    
    try:
        v1.create_namespace(body)
        print(f"âœ… Complete namesapce creation '{name}'.")
    except client.ApiException as e:
        if e.status == 409:  # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•  ê²½ìš°
            print(f"âš ï¸ Namespace '{name}' is already exist.")
        else:
            print(f"âŒ Failed namespace creation \n {e}")

def create_deployment(namespace: str, name: str, image: str, replicas: int = 1, container_port: int = 80):
    """Deployment ìƒì„±"""
    deployment = client.V1Deployment(
        metadata=client.V1ObjectMeta(name=name),
        spec=client.V1DeploymentSpec(
            replicas=replicas,
            selector=client.V1LabelSelector(
                match_labels={"app": name}
            ),
            template=client.V1PodTemplateSpec(
                metadata=client.V1ObjectMeta(labels={"app": name}),
                spec=client.V1PodSpec(
                    containers=[
                        client.V1Container(
                            name=name,
                            image=image,
                            ports=[client.V1ContainerPort(container_port=container_port)]
                        )
                    ]
                )
            )
        )
    )
    try:
        apps_v1.create_namespaced_deployment(namespace=namespace, body=deployment)
        print(f"âœ… Deployment '{name}' is created in namespace '{namespace}'.")
    except client.ApiException as e:
        print(f"âŒ Deployment creation failed: {e}")


def create_nautilus_service(
    service_name: str,
    selector_labels: dict,
    namespace: str = "nautilus",
):

    ports = [
        {"name": "fed", "port": 8002, "targetPort": 8002, "protocol": "TCP"},
        {"name": "admin", "port": 8003, "targetPort": 8003, "protocol": "TCP"}
    ]
    
    service_ports = [
        client.V1ServicePort(
            name=p["name"],
            port=p["port"],
            target_port=p["targetPort"],
            protocol=p["protocol"]
        ) for p in ports
    ]

    service = client.V1Service(
        metadata=client.V1ObjectMeta(name=service_name),
        spec=client.V1ServiceSpec(
            selector=selector_labels,  # ì˜ˆ: {"app": "nautilus"}
            ports=service_ports,
            type="ClusterIP"
        )
    )

    try:
        v1.create_namespaced_service(namespace=namespace, body=service)
        print(f"âœ… Service '{service_name}' created successfully")
    except client.exceptions.ApiException as e:
        print(f"âŒ Failed to create service: {e}")



def create_client_deployment(project_id: str ,site: int, node_name: str, namespace: str = "nautilus", image: str = "nautilus-pv-updated:latest", replicas: int = 1, use_gpu: bool = True):
    """Clientìš© Deployment ìƒì„± í•¨ìˆ˜ (GPU ì‚¬ìš© ì—¬ë¶€ ì„ íƒ ê°€ëŠ¥)"""

    # ë¦¬ì†ŒìŠ¤ ì„¤ì • ë¶„ê¸°
    limits = {
        "memory": "10Gi",
        "cpu": "4"
    }
    requests = {
        "memory": "6Gi",
        "cpu": "2"
    }
    if use_gpu:
        limits["nvidia.com/gpu"] = "1"
        requests["nvidia.com/gpu"] = "1"

    deployment = client.V1Deployment(
        api_version="apps/v1",
        kind="Deployment",
        metadata=client.V1ObjectMeta(
            name=f"{project_id}-site-{site}",
            labels={"app": namespace}
        ),
        spec=client.V1DeploymentSpec(
            replicas=1,
            selector=client.V1LabelSelector(
                match_labels={"app": namespace}
            ),
            template=client.V1PodTemplateSpec(
                metadata=client.V1ObjectMeta(
                    labels={"app": namespace}
                ),
                spec=client.V1PodSpec(
                    node_selector={"kubernetes.io/hostname": node_name},
                    containers=[
                        client.V1Container(
                            name=f"{project_id}-site-{site}",
                            image=image,
                            image_pull_policy="Never",
                            resources=client.V1ResourceRequirements(
                                limits=limits,
                                requests=requests
                            ),
                            args=[
                                "-u", "-m", "nvflare.private.fed.app.client.client_train",
                                "-m", f"/workspace/nvfl/{project_id}-site-{site}", "-s", "fed_client.json",
                                "--set", "secure_train=true", f"uid={project_id}-site-{site}",
                                "config_folder=config", "org=nvidia"
                            ],
                            command=["/bin/bash", "-c", f"pip install --upgrade nvflare==2.5.2 torch tensorboard torchvision && /workspace/nautilus/nautilus/workspace/provision/{project_id}/prod_00/site-{site}/startup/sub_start.sh"]
                        )
                    ]
                )
            )
        )
    )

    # Create the Deployment in the cluster
    api_instance = client.AppsV1Api()

    try:
        api_instance.create_namespaced_deployment(namespace=namespace, body=deployment)
        print("âœ… Deployment created successfully!")
    except client.exceptions.ApiException as e:
        print(f"âŒ Exception when creating deployment: {e}")

def create_server_deployment(project_id: str , node_name: str, namespace: str = "nautilus", image: str = "nautilus-pv-updated:latest", replicas: int = 1, use_gpu: bool = True):
    """Deployment ìƒì„± (role ì—†ì´ node_name ê¸°ë°˜ìœ¼ë¡œ ë°°í¬, GPU ì‚¬ìš© ì—¬ë¶€ ì„ íƒ ê°€ëŠ¥)"""

    # ë¦¬ì†ŒìŠ¤ ì„¤ì • ë¶„ê¸°
    limits = {
        "memory": "8Gi",
        "cpu": "4"
    }
    requests = {
        "memory": "4Gi",
        "cpu": "2"
    }

    if use_gpu:
        limits["nvidia.com/gpu"] = "1"
        requests["nvidia.com/gpu"] = "1"
    deployment = client.V1Deployment(
        api_version="apps/v1",
        kind="Deployment",
        metadata=client.V1ObjectMeta(
            name=f"{project_id}-server",
            labels={"app": namespace}
        ),
        spec=client.V1DeploymentSpec(
            replicas=1,
            selector=client.V1LabelSelector(
                match_labels={"app": namespace}
            ),
            template=client.V1PodTemplateSpec(
                metadata=client.V1ObjectMeta(
                    labels={"app": namespace}
                ),
                spec=client.V1PodSpec(
                    node_selector={"kubernetes.io/hostname": node_name}, 
                    containers=[
                        client.V1Container(
                            name=f"server",
                            image=image,
                            image_pull_policy="Never",
                            resources=client.V1ResourceRequirements(
                                limits=limits,
                                requests=requests
                            ),
                            args=[
                                "-u", "-m", "nvflare.private.fed.app.server.server_train",
                                "-m", f"/workspace/nvfl/{project_id}-server", "-s", "fed_server.json",
                                "--set", "secure_train=true", "config_folder=config", "org=nvidia"
                            ],
                            command=["/bin/bash", "-c", f"pip install --upgrade nvflare==2.5.2 torch tensorboard torchvision && /workspace/nautilus/nautilus/workspace/provision/{project_id}/prod_00/mylocalhost/startup/sub_start.sh"]
                        )
                    ]
                )
            )
        )
    )

    # Create the Deployment in the cluster
    api_instance = client.AppsV1Api()
    namespace = namespace  # Change if deploying to a different namespace

    try:
        api_instance.create_namespaced_deployment(namespace=namespace, body=deployment)
        print("Deployment created successfully!")
    except client.exceptions.ApiException as e:
        print(f"Exception when creating deployment: {e}")


# --- Kubernetes ì‹¤í–‰ í•¨ìˆ˜ë“¤ --- #
# def connect_get_namespaced_pod_exec(namespace: str, pod_name: str, command: str):
#     return stream(
#         v1.connect_get_namespaced_pod_exec,
#         name=pod_name,
#         namespace=namespace,
#         command=shlex.split(command),
#         stderr=True,
#         stdin=False,
#         stdout=True,
#         tty=False
#     )
    
def connect_get_namespaced_pod_exec(pod_name: str, command: str, namespace: str = "nautilus"):
    wrapped_command = ["/bin/bash", "-c", command]
    return stream(
        v1.connect_get_namespaced_pod_exec,
        name=pod_name,
        namespace=namespace,
        command=wrapped_command,
        stderr=True,
        stdin=False,
        stdout=True,
        tty=False
    )

    
def connect_get_namespaced_pod_portforward(namespace: str, pod_name: str, ports: list):
    """Podì˜ í¬íŠ¸ë¥¼ í¬íŠ¸í¬ì›Œë”©"""
    return v1.connect_get_namespaced_pod_portforward(pod_name, namespace, ports=ports)

def connect_get_namespaced_service_proxy(namespace: str, service_name: str):
    """íŠ¹ì • Serviceì— Proxy ì—°ê²°"""
    return v1.connect_get_namespaced_service_proxy(service_name, namespace)

def copy_to_container(
    pod_name: str,
    namespace: str,
    local_file_path: str,
    container_path: str,
    type: str = "file",
    container_name: str = None  # ğŸ” ì¶”ê°€
):
    """
    ì£¼ì–´ì§„ íŒŒì¼ì„ Kubernetes Pod ë‚´ ì»¨í…Œì´ë„ˆë¡œ ë³µì‚¬í•˜ëŠ” í•¨ìˆ˜.

    :param pod_name: íŒŒì¼ì„ ë³µì‚¬í•  Podì˜ ì´ë¦„
    :param namespace: Podê°€ ì†í•œ namespace
    :param local_file_path: ë¡œì»¬ ì‹œìŠ¤í…œì—ì„œ ë³µì‚¬í•  íŒŒì¼ ê²½ë¡œ
    :param container_path: ì»¨í…Œì´ë„ˆ ë‚´ì—ì„œ ë³µì‚¬í•  ëŒ€ìƒ ê²½ë¡œ
    :param type: "file" ë˜ëŠ” "folder" (ê¸°ë³¸ê°’: "file")
    :param container_name: ì»¨í…Œì´ë„ˆ ì´ë¦„ ëª…ì‹œ (ì„ íƒì )
    """
    print(f"copy_to_container: namespace: {namespace}, pod_name: {pod_name}, local_file_path: {local_file_path}, container_path: {container_path}, type: {type}")

    try:
        command = ["kubectl", "cp"]

        if container_name:
            command += ["-c", container_name]

        if type == "folder":
            command += ["-r"]

        command += [local_file_path, f"{namespace}/{pod_name}:{container_path}"]

        print(f"[INFO] Running command: {' '.join(command)}")
        subprocess.run(command, check=True)
        print(f"[SUCCESS] File successfully copied to {pod_name} in container!")

    except subprocess.CalledProcessError as e:
        print(f"[ERROR] File copy failed: {e}")
        print(f"[DEBUG] Check if pod exists: kubectl get pods -n {namespace}")
        print(f"[DEBUG] Check if namespace exists: kubectl get ns")
        
if __name__ == "__main__":
    f = open('api_result.json', 'w')

    print("########################### Print Nodes : ", file=f)
    print(list_node(), file=f)
    print("########################### Print Pod : ", file=f)
    print(list_pod_for_all_namespaces(), file=f)
    print("########################### Print Deployment : ", file=f)
    print(list_deployment_for_all_namespace(), file=f)

